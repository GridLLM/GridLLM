name: Integration Tests

on:
    push:
        branches: [main, staging]
    pull_request:
        branches: [main, staging]

jobs:
    integration-test:
        runs-on: ubuntu-latest

        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Set up Docker Buildx
              uses: docker/setup-buildx-action@v3

            - name: Start Ollama container
              run: |
                  docker run -d \
                    --name ollama-test \
                    -p 11434:11434 \
                    ollama/ollama:latest

                  # Wait for Ollama to be ready
                  echo "Waiting for Ollama to start..."
                  timeout 120 bash -c 'until curl -f http://localhost:11434/api/version; do sleep 5; done'
                  echo "Ollama is ready"

                  # Pull qwen2.5:0.5b on Ollama POST /api/pull
                  echo "Pulling qwen2.5:0.5b model..."
                  timeout 120 bash -c 'until curl -X POST -H "Content-Type: application/json" -d "{\"model\": \"qwen2.5:0.5b\"}" http://localhost:11434/api/pull; do sleep 5; done'
                  echo "Model qwen2.5:0.5b is ready"

            - name: Create .env file for testing
              run: |
                  cat > .env << EOF
                  NODE_ENV=test
                  SERVER_PORT=4000
                  CLIENT_PORT=3000
                  REDIS_PORT=6379
                  REDIS_PASSWORD=
                  REDIS_DB=0
                  REDIS_KEY_PREFIX=GridLLM:
                  WORKER_ID=worker-ci-001
                  OLLAMA_HOST=ollama-test
                  OLLAMA_PORT=11434
                  OLLAMA_PROTOCOL=http
                  API_KEY=test-api-key
                  LOG_LEVEL=info
                  EOF

            - name: Build Docker images
              run: |
                  docker compose build --no-cache

            - name: Start services and connect Ollama
              run: |
                  # Start compose services first to create the network
                  npm run bundle:full

                  # Find the compose network and connect Ollama to it
                  COMPOSE_NETWORK=$(docker network ls --filter name=gridllm --format "{{.Name}}" | head -1)
                  echo "Connecting ollama-test to compose network: $COMPOSE_NETWORK"
                  docker network connect "$COMPOSE_NETWORK" ollama-test

                  # Verify connection
                  echo "Networks for ollama-test:"
                  docker inspect ollama-test --format='{{range $k, $v := .NetworkSettings.Networks}}{{$k}} {{end}}'

            - name: Wait for services to be healthy
              run: |
                  echo "Waiting for services to start..."
                  sleep 30

                  # Wait for Redis to be healthy
                  timeout 30 bash -c 'until docker compose exec -T redis redis-cli ping; do sleep 2; done'
                  echo "Redis is healthy"

                  # Wait for Server to be healthy
                  timeout 30 bash -c 'until curl -f http://localhost:4000/health; do sleep 5; done'
                  echo "Server is healthy"

                  # Wait for Client to be healthy
                  timeout 30 bash -c 'until curl -f http://localhost:3000/health; do sleep 5; done'
                  echo "Client is healthy"

            - name: Check if services are healthy
              run: |
                  echo "Testing server health endpoint..."
                  curl -f http://localhost:4000/health

                  echo "Testing client health endpoint..."
                  curl -f http://localhost:3000/health

                  echo "Testing Redis connection..."
                  docker compose exec -T redis redis-cli ping

                  echo "Testing Ollama connection..."
                  curl -f http://localhost:11434/api/version

                  echo "All services are running and healthy!"

            - name: Test /ollama Endpoints
              run: |
                  echo "Testing POST /ollama/api/generate"
                  curl -f -X POST -H "Content-Type: application/json" -d '{"prompt": "What country is New York in? Answer in just the country.", "model": "qwen2.5:0.5b"}' http://localhost:4000/api/generate

            - name: Show service logs on failure
              if: failure()
              run: |
                  echo "=== Server logs ==="
                  docker compose logs server
                  echo "=== Client logs ==="
                  docker compose logs client
                  echo "=== Redis logs ==="
                  docker compose logs redis
                  echo "=== Ollama logs ==="
                  docker logs ollama-test 2>/dev/null || echo "Ollama container not running"

            - name: Stop and cleanup
              if: always()
              run: |
                  docker compose down -v
                  docker stop ollama-test 2>/dev/null || true
                  docker rm ollama-test 2>/dev/null || true
                  docker system prune -f
