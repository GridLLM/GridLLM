# GridLLM Global Environment Configuration
# Copy this file to .env and customize the values

# Environment
NODE_ENV=development

# Network Configuration
DOCKER_NETWORK=bridge

# Server Configuration
SERVER_PORT=4000
SERVER_CONTAINER_NAME=llmama-server-container
SERVER_IMAGE_NAME=llmama-server

# Client Configuration
CLIENT_PORT=3000
CLIENT_CONTAINER_NAME=llmama-client-container
CLIENT_IMAGE_NAME=llmama-client
WORKER_ID=worker-docker-001

# Redis Configuration
REDIS_HOST=host.docker.internal
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_KEY_PREFIX=GridLLM:

# Ollama Configuration
OLLAMA_HOST=host.docker.internal
OLLAMA_PORT=11434
OLLAMA_PROTOCOL=http
OLLAMA_TIMEOUT=300000
OLLAMA_MAX_RETRIES=3

# Worker Configuration
WORKER_CONCURRENCY=2
WORKER_MAX_CONCURRENT_JOBS=1
WORKER_POLL_INTERVAL=1000
WORKER_RESOURCE_CHECK_INTERVAL=10000

# Performance Thresholds
MAX_CPU_USAGE=80
MAX_MEMORY_USAGE=85
MAX_GPU_MEMORY_USAGE=90
MIN_AVAILABLE_MEMORY_MB=1024

# Security
API_KEY=worker-api-key

# Logging
LOG_LEVEL=info
HEALTH_CHECK_INTERVAL=60000

# Task Configuration
TASK_TIMEOUT=600000
TASK_RETRY_ATTEMPTS=3
TASK_RETRY_DELAY=5000

# Rate Limiting
RATE_LIMIT_WINDOW=60000
RATE_LIMIT_MAX_REQUESTS=100

# CORS
CORS_ORIGIN=*

# Job Configuration
JOB_TIMEOUT=600000
WORKER_TIMEOUT=300000
WORKER_HEARTBEAT_TIMEOUT=60000
WORKER_CLEANUP_INTERVAL=30000
MAX_CONCURRENT_JOBS_PER_WORKER=1
